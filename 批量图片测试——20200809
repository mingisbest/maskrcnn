#参考demo程序

#报错，len（images）must be equal to batch——size，改变config中gpu与image_per_gpu,相乘等于batch_size

#要用最新的weight。即最新的h5文件，保证训练的过程是完善的



import os

import sys

import random

import math

import numpy as np

import skimage.io

import matplotlib

import matplotlib.pyplot as plt

from mrcnn.config import Config

# Root directory of the project

ROOT_DIR = os.path.abspath("")



# Import Mask RCNN

sys.path.append(ROOT_DIR)  # To find local version of the library

from mrcnn import utils

import mrcnn.model as modellib

from mrcnn import visualize

from mrcnn import utils
from mrcnn import visualize
from mrcnn.visualize import display_images
import mrcnn.model as modellib
from mrcnn.model import log






# Import COCO config

sys.path.append(os.path.join(ROOT_DIR, "samples/celldata/"))  # To find local version

#import coco



%matplotlib inline 



# Directory to save logs and trained model

MODEL_DIR = os.path.join(ROOT_DIR, "logs")



# Local path to trained weights file

COCO_MODEL_PATH = os.path.join(ROOT_DIR, "mask_rcnn_cell_0006.h5")

# Download COCO trained weights from Releases if needed

if not os.path.exists(COCO_MODEL_PATH):

    utils.download_trained_weights(COCO_MODEL_PATH)



# Directory of images to run detection on

IMAGE_DIR = os.path.join(ROOT_DIR, "images")

print(COCO_MODEL_PATH)





class ShapesConfig(Config):

    """Configuration for training on the toy shapes dataset.

    Derives from the base Config class and overrides values specific

    to the toy shapes dataset.

    """

    # Give the configuration a recognizable name

    NAME = "cell"

 

    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each

    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).

    GPU_COUNT = 1

    IMAGES_PER_GPU = 1

 

    # Number of classes (including background)

    NUM_CLASSES = 1 + 1  # background + 1 shapes  注意这里我是4类，所以是4+1

 

    # Use small images for faster training. Set the limits of the small side

    # the large side, and that determines the image shape.

    IMAGE_MIN_DIM = 256

    IMAGE_MAX_DIM = 1024

 # Don't exclude based on confidence. Since we have two classes
    # then 0.5 is the minimum anyway as it picks between nucleus and BG
    DETECTION_MIN_CONFIDENCE = 0.9

    # Backbone network architecture
    # Supported values are: resnet50, resnet101
    BACKBONE = "resnet50"

      # Length of square anchor side in pixels
    #RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)
    
    RPN_ANCHOR_SCALES = (16 * 6, 32 * 6, 64 * 6, 128 * 6, 256 * 6)  

    # ROIs kept after non-maximum supression (training and inference)
    POST_NMS_ROIS_TRAINING = 4000
    POST_NMS_ROIS_INFERENCE = 8000

    # Non-max suppression threshold to filter RPN proposals.
    # You can increase this during training to generate more propsals.
    RPN_NMS_THRESHOLD = 0.9

    # How many anchors per image to use for RPN training
    RPN_TRAIN_ANCHORS_PER_IMAGE = 640

    # Image mean (RGB)
    #MEAN_PIXEL = np.array([43.53, 39.56, 48.22])

    # If enabled, resizes instance masks to a smaller size to reduce
    # memory load. Recommended when using high-resolution images.
    USE_MINI_MASK = True
    MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask

    # Number of ROIs per image to feed to classifier/mask heads
    # The Mask RCNN paper uses 512 but often the RPN doesn't generate
    # enough positive proposals to fill this and keep a positive:negative
    # ratio of 1:3. You can increase the number of proposals by adjusting
    # the RPN NMS threshold.
    TRAIN_ROIS_PER_IMAGE = 1280

    # Maximum number of ground truth instances to use in one image
    MAX_GT_INSTANCES = 2000

    # Max number of final detections per image
    DETECTION_MAX_INSTANCES = 4000
    
      # Use a small epoch since the data is simple

    STEPS_PER_EPOCH = 1000     #  每个epoch中迭代的step，最好不要改动

 

    # use small validation steps since the epoch is small

    VALIDATION_STEPS = 500


 

 

config = ShapesConfig()

config.display()





# Create model object in inference mode.

model = modellib.MaskRCNN(mode="inference", model_dir=MODEL_DIR, config=config)



# Load weights trained on MS-COCO

model.load_weights(COCO_MODEL_PATH, by_name=True)





# COCO Class names

# Index of the class in the list is its ID. For example, to get ID of

# the teddy bear class, use: class_names.index('teddy bear')

class_names = ['BG', 'cell']





# Load a random image from the images folder

#file_names = next(os.walk(IMAGE_DIR))[2]  #可以改为下边一行，但是图片数量要等于batch_size

image = skimage.io.imread("DAY0-2-10X.png")



# Run detection

results = model.detect([image], verbose=20)



# Visualize results

r = results[0]

visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], 

                            class_names, r['scores'],show_bbox=False)





#参考demo程序

#报错，len（images）must be equal to batch——size，改变config中gpu与image_per_gpu,相乘等于batch_size

#要用最新的weight。即最新的h5文件，保证训练的过程是完善的



import os

import sys

import random

import math

import numpy as np

import skimage.io

import matplotlib

import matplotlib.pyplot as plt

from mrcnn.config import Config

# Root directory of the project

ROOT_DIR = os.path.abspath("")



# Import Mask RCNN

sys.path.append(ROOT_DIR)  # To find local version of the library

from mrcnn import utils

import mrcnn.model as modellib

from mrcnn import visualize

from mrcnn import utils
from mrcnn import visualize
from mrcnn.visualize import display_images
import mrcnn.model as modellib
from mrcnn.model import log






# Import COCO config

sys.path.append(os.path.join(ROOT_DIR, "samples/celldata/"))  # To find local version

#import coco



%matplotlib inline 



# Directory to save logs and trained model

MODEL_DIR = os.path.join(ROOT_DIR, "logs")



# Local path to trained weights file

COCO_MODEL_PATH = os.path.join(ROOT_DIR, "mask_rcnn_cell_0006.h5")

# Download COCO trained weights from Releases if needed

if not os.path.exists(COCO_MODEL_PATH):

    utils.download_trained_weights(COCO_MODEL_PATH)



# Directory of images to run detection on

IMAGE_DIR = os.path.join(ROOT_DIR, "images1")

print(COCO_MODEL_PATH)





class ShapesConfig(Config):

    """Configuration for training on the toy shapes dataset.

    Derives from the base Config class and overrides values specific

    to the toy shapes dataset.

    """

    # Give the configuration a recognizable name

    NAME = "cell"

 

    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each

    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).

    GPU_COUNT = 1

    IMAGES_PER_GPU = 1

 

    # Number of classes (including background)

    NUM_CLASSES = 1 + 1  # background + 1 shapes  注意这里我是4类，所以是4+1

 

    # Use small images for faster training. Set the limits of the small side

    # the large side, and that determines the image shape.

    IMAGE_MIN_DIM = 256

    IMAGE_MAX_DIM = 1024

 # Don't exclude based on confidence. Since we have two classes
    # then 0.5 is the minimum anyway as it picks between nucleus and BG
    DETECTION_MIN_CONFIDENCE = 0

    # Backbone network architecture
    # Supported values are: resnet50, resnet101
    BACKBONE = "resnet50"

      # Length of square anchor side in pixels
    #RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)
    
    RPN_ANCHOR_SCALES = (16 * 6, 32 * 6, 64 * 6, 128 * 6, 256 * 6)  

    # ROIs kept after non-maximum supression (training and inference)
    POST_NMS_ROIS_TRAINING = 4000
    POST_NMS_ROIS_INFERENCE = 8000

    # Non-max suppression threshold to filter RPN proposals.
    # You can increase this during training to generate more propsals.
    RPN_NMS_THRESHOLD = 0.9

    # How many anchors per image to use for RPN training
    RPN_TRAIN_ANCHORS_PER_IMAGE = 640

    # Image mean (RGB)
    #MEAN_PIXEL = np.array([43.53, 39.56, 48.22])

    # If enabled, resizes instance masks to a smaller size to reduce
    # memory load. Recommended when using high-resolution images.
    USE_MINI_MASK = True
    MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask

    # Number of ROIs per image to feed to classifier/mask heads
    # The Mask RCNN paper uses 512 but often the RPN doesn't generate
    # enough positive proposals to fill this and keep a positive:negative
    # ratio of 1:3. You can increase the number of proposals by adjusting
    # the RPN NMS threshold.
    TRAIN_ROIS_PER_IMAGE = 1280

    # Maximum number of ground truth instances to use in one image
    MAX_GT_INSTANCES = 2000

    # Max number of final detections per image
    DETECTION_MAX_INSTANCES = 4000
    
      # Use a small epoch since the data is simple

    STEPS_PER_EPOCH = 1000     #  每个epoch中迭代的step，最好不要改动

 

    # use small validation steps since the epoch is small

    VALIDATION_STEPS = 500


 

 

config = ShapesConfig()

config.display()





# Create model object in inference mode.

model = modellib.MaskRCNN(mode="inference", model_dir=MODEL_DIR, config=config)



# Load weights trained on MS-COCO

model.load_weights(COCO_MODEL_PATH, by_name=True)





# COCO Class names

# Index of the class in the list is its ID. For example, to get ID of

# the teddy bear class, use: class_names.index('teddy bear')

class_names = ['BG', 'cell']

'''# Load a random image from the images folder

#file_names = next(os.walk(IMAGE_DIR))[2]  #可以改为下边一行，但是图片数量要等于batch_size

image = skimage.io.imread("DAY0-2-10X.png")



# Run detection

results = model.detect([image], verbose=20)



# Visualize results

r = results[0]

visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], 

                            class_names, r['scores'],show_bbox=False)
'''







count = os.listdir(IMAGE_DIR)
print(count)

for i in range(0,len(count)):

    path = os.path.join(IMAGE_DIR, count[i])

    if os.path.isfile(path):

        file_names = next(os.walk(IMAGE_DIR))[2]

        image = skimage.io.imread(os.path.join(IMAGE_DIR, count[i]))

        # Run detection

        results = model.detect([image], verbose=1)

        r = results[0]

        visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'],  class_names, r['scores'],colors=None, captions=None)

        fig = plt.gcf()
        width =1024
        height = 1024

        fig.set_size_inches(width / 100.0, height / 100.0)  # 输出原始图像width*height的像素

        plt.gca().xaxis.set_major_locator(plt.NullLocator())

        plt.gca().yaxis.set_major_locator(plt.NullLocator())

        plt.subplots_adjust(top=1, bottom=0, left=0, right=1, hspace=0, wspace=0)

        plt.margins(0, 0)

        plt.savefig("./test_results/%3s.jpg" %(str(count[4:7])),pad_inches=0.0)

        plt.show()
